{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## all imports\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import urllib.request as urllib2\n",
    "import bs4 #this is beautiful soup\n",
    "import time\n",
    "import operator\n",
    "import socket\n",
    "import pickle\n",
    "import re # regular expressions\n",
    "\n",
    "from pandas import Series\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import urllib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tweepy\n",
    "# import seaborn as sns\n",
    "# sns.set_context(\"talk\")\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "# from secret import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "API registrations\n",
    "=================\n",
    "\n",
    "If you would like to run all the examples in this notebook, you need to register for the following APIs:\n",
    "\n",
    "* Rotten Tomatoes\n",
    "\n",
    "http://developer.rottentomatoes.com/member/register\n",
    "\n",
    "* Twitter\n",
    "\n",
    "https://apps.twitter.com/app/new\n",
    "\n",
    "* Twitter instructions\n",
    "\n",
    "https://twittercommunity.com/t/how-to-get-my-api-key/7033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "CS109\n",
    "=====\n",
    "\n",
    "Verena Kaynig-Fittkau, Joe Blitzstein, Hanspeter Pfister\n",
    "\n",
    "* vkaynig@seas.harvard.edu\n",
    "* staff@cs109.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Announcements\n",
    "==============\n",
    "\n",
    "* Over 400 sign ups on github!\n",
    "* If you are still missing, fill out the survey, time is running out!\n",
    "* Make sure you are on Piazza!\n",
    "\n",
    "\n",
    "* More [git help](https://www.youtube.com/channel/UC0-KaiZFXBlGOFN71YsEV8g/videos)\n",
    "\n",
    "\n",
    "* HW0 is due on Thursday \n",
    "* HW1 is coming out on Thursday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Todays lecture:\n",
    "===============\n",
    "\n",
    "* introduction to pandas\n",
    "    - read a table\n",
    "    - do some plots\n",
    "\n",
    "* all about data scraping\n",
    "* ***What is it? ***\n",
    "* How to do it:\n",
    "    - from a website\n",
    "    - with an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "IPython Notebooks:\n",
    "===================\n",
    "\n",
    "![IPython](images/ipython.png \"IPython\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "IPython Notebooks:\n",
    "===================\n",
    "\n",
    "* These slides are an IPython notebook!\n",
    "* https://github.com/damianavila/live_reveal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Hello CS109\"\n",
    "\n",
    "print \"I love IPython\"\n",
    "\n",
    "# Ipython notebook have tab completion!\n",
    "# and inbuild help\n",
    "  \n",
    "a = np.zeros(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "General advice about programming\n",
    "==================================\n",
    "\n",
    "* You will find nearly everything on google\n",
    "* Try: length of a list in python\n",
    "* A programmer is someone who can turn stack overflow snippets into running code\n",
    "* Use tab completion\n",
    "* Make your variable names meaningful\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to load a table\n",
    "===================\n",
    "\n",
    "* we use Pandas for this\n",
    "* Pandas can do a __lot__ more\n",
    "* more about it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The MovieLens data\n",
    "===================\n",
    "\n",
    "http://grouplens.org/datasets/movielens/\n",
    "\n",
    "![Grouplens](images/grouplens.jpg \"Grouplens\")\n",
    "\n",
    "Example inspired by [Greg Reda](http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read the user data\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ko/git/cs109-2015/Lectures /Users/ko/git/cs109-2015/Lectures/data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['allbut.pl',\n",
       " 'mku.sh',\n",
       " 'README',\n",
       " 'u.data',\n",
       " 'u.genre',\n",
       " 'u.info',\n",
       " 'u.item',\n",
       " 'u.occupation',\n",
       " 'u.user',\n",
       " 'u1.base',\n",
       " 'u1.test',\n",
       " 'u2.base',\n",
       " 'u2.test',\n",
       " 'u3.base',\n",
       " 'u3.test',\n",
       " 'u4.base',\n",
       " 'u4.test',\n",
       " 'u5.base',\n",
       " 'u5.test',\n",
       " 'ua.base',\n",
       " 'ua.test',\n",
       " 'ub.base',\n",
       " 'ub.test']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "data_dir = cwd + \"/data\"\n",
    "print(cwd, data_dir)\n",
    "\n",
    "csv_path = data_dir + \"/ml-100k\" \n",
    "os.listdir(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex  occupation zip_code\n",
       "0        1   24   M  technician    85711\n",
       "1        2   53   F       other    94043\n",
       "2        3   23   M      writer    32067\n",
       "3        4   24   M  technician    43537\n",
       "4        5   33   F       other    15213"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in column names for each CSV\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "\n",
    "users = pd.read_csv(csv_path+\"/u.user\", \n",
    "    sep='|', names=u_cols)\n",
    "\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read the ratings\n",
    "============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0      196       242       3       881250949\n",
       "1      186       302       3       891717742\n",
       "2       22       377       1       878887116\n",
       "3      244        51       2       880606923\n",
       "4      166       346       1       886397596"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(csv_path + '/u.data', \n",
    "    sep='\\t', names=r_cols)\n",
    "\n",
    "ratings.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now data about the movies\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id              title release_date  video_release_date  \\\n",
       "0         1   Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "1         2   GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "2         3  Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "3         4  Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "4         5     Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                            imdb_url  \n",
       "0  http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n",
       "1  http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n",
       "2  http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n",
       "3  http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n",
       "4  http://us.imdb.com/M/title-exact?Copycat%20(1995)  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first five columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date', \n",
    "            'video_release_date', 'imdb_url']\n",
    "\n",
    "movies = pd.read_csv(csv_path + '/u.item', \n",
    "    sep='|', names=m_cols, usecols=range(5), encoding='cp1252')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get information about data\n",
    "======================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id                int64\n",
       "title                  object\n",
       "release_date           object\n",
       "video_release_date    float64\n",
       "imdb_url               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.dtypes\n",
    "# *** Why only those two columns? ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>video_release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1682.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>841.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>485.695893</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>421.250000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>841.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1261.750000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1682.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          movie_id  video_release_date\n",
       "count  1682.000000                 0.0\n",
       "mean    841.500000                 NaN\n",
       "std     485.695893                 NaN\n",
       "min       1.000000                 NaN\n",
       "25%     421.250000                 NaN\n",
       "50%     841.500000                 NaN\n",
       "75%    1261.750000                 NaN\n",
       "max    1682.000000                 NaN"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Selecting data\n",
    "==============\n",
    "\n",
    "* DataFrame => group of Series with shared index\n",
    "* single DataFrame column => Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    technician\n",
       "1         other\n",
       "2        writer\n",
       "3    technician\n",
       "4         other\n",
       "Name: occupation, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(users.head())\n",
    "users['occupation'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occupation</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>technician</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   occupation sex\n",
       "0  technician   M\n",
       "1       other   F"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## *** Where did the nice design go? ***\n",
    "columns_you_want = ['occupation', 'sex'] \n",
    "users[columns_you_want].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  age sex  occupation zip_code\n",
      "0        1   24   M  technician    85711\n",
      "1        2   53   F       other    94043\n",
      "2        3   23   M      writer    32067\n",
      "3        4   24   M  technician    43537\n",
      "4        5   33   F       other    15213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "user_id                4\n",
       "age                   24\n",
       "sex                    M\n",
       "occupation    technician\n",
       "zip_code           43537\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(users.head())\n",
    "users.iloc[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Filtering data\n",
    "==============\n",
    "\n",
    "Select users older than 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>91344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>05201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  age sex     occupation zip_code\n",
       "1        2   53   F          other    94043\n",
       "4        5   33   F          other    15213\n",
       "5        6   42   M      executive    98101\n",
       "6        7   57   M  administrator    91344\n",
       "7        8   36   M  administrator    05201"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldUsers = users[users.age > 25]\n",
    "oldUsers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz:\n",
    "=====\n",
    "\n",
    "* show users aged 40 and male\n",
    "\n",
    "* show the mean age of female programmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>91344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>90703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>educator</td>\n",
       "      <td>29206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>M</td>\n",
       "      <td>scientist</td>\n",
       "      <td>55106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  age sex     occupation zip_code\n",
       "5         6   42   M      executive    98101\n",
       "6         7   57   M  administrator    91344\n",
       "9        10   53   M         lawyer    90703\n",
       "12       13   47   M       educator    29206\n",
       "13       14   45   M      scientist    55106"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# users aged 40 AND male\n",
    "# your code here\n",
    "users[(users[\"age\"]>40) & (users[\"sex\"]==\"M\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of female programmers 0.6362672322375398\n",
      "          user_id        age\n",
      "count    6.000000   6.000000\n",
      "mean   411.166667  32.166667\n",
      "std    149.987222   5.115336\n",
      "min    292.000000  26.000000\n",
      "25%    313.000000  28.250000\n",
      "50%    378.000000  32.000000\n",
      "75%    416.750000  36.500000\n",
      "max    698.000000  38.000000\n",
      "avg age of female programmers 32.166666666666664\n"
     ]
    }
   ],
   "source": [
    "## users who are female and programmers\n",
    "# your code here\n",
    "f_p = users[(users[\"occupation\"]==\"programmer\") & (users[\"sex\"]==\"F\")]\n",
    "f_p.head()\n",
    "## show statistic summary or compute mean\n",
    "# your code here\n",
    "print(\"percentage of female programmers\", 100*f_p.shape[0]/users.shape[0])\n",
    "print(f_p.describe())\n",
    "print(\"avg age of female programmers\", f_p[\"age\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Split-apply-combine\n",
    "===================\n",
    "\n",
    "* splitting the data into groups based on some criteria\n",
    "* applying a function to each group independently\n",
    "* combining the results into a data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Split-apply-combine\n",
    "===================\n",
    "\n",
    "<img src=http://i.imgur.com/yjNkiwL.png></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Find Diligent Users\n",
    "===================\n",
    "\n",
    "* split data per user ID\n",
    "* count ratings\n",
    "* combine result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0      196       242       3       881250949\n",
       "1      186       302       3       891717742\n",
       "2       22       377       1       878887116\n",
       "3      244        51       2       880606923\n",
       "4      166       346       1       886397596"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "grouped_data = ratings.groupby('user_id')\n",
    "#grouped_data = ratings['movie_id'].groupby(ratings['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         movie_id  rating  unix_timestamp\n",
       "user_id                                  \n",
       "1             272     272             272\n",
       "2              62      62              62\n",
       "3              54      54              54\n",
       "4              24      24              24\n",
       "5             175     175             175"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## count and combine\n",
    "ratings_per_user = grouped_data.count()\n",
    "ratings_per_user.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz\n",
    "====\n",
    "\n",
    "* get the average rating per movie\n",
    "* advanced: get the movie titles with the highest average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477.011062</td>\n",
       "      <td>3.878319</td>\n",
       "      <td>8.828054e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>492.007634</td>\n",
       "      <td>3.206107</td>\n",
       "      <td>8.834174e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459.133333</td>\n",
       "      <td>3.033333</td>\n",
       "      <td>8.822269e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469.497608</td>\n",
       "      <td>3.550239</td>\n",
       "      <td>8.827175e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>439.372093</td>\n",
       "      <td>3.302326</td>\n",
       "      <td>8.825882e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id    rating  unix_timestamp\n",
       "movie_id                                      \n",
       "1         477.011062  3.878319    8.828054e+08\n",
       "2         492.007634  3.206107    8.834174e+08\n",
       "3         459.133333  3.033333    8.822269e+08\n",
       "4         469.497608  3.550239    8.827175e+08\n",
       "5         439.372093  3.302326    8.825882e+08"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## split data\n",
    "# your code here\n",
    "\n",
    "movie_ratings = ratings.groupby(by=\"movie_id\")\n",
    "movie_ratings_mean = movie_ratings.mean()\n",
    "movie_ratings_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>3.878319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>3.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>3.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>3.550239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>3.302326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title release_date  video_release_date  \\\n",
       "movie_id                                                       \n",
       "1          Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2          GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3         Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4         Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5            Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   imdb_url   ratings  \n",
       "movie_id                                                               \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...  3.878319  \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...  3.206107  \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...  3.033333  \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...  3.550239  \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)  3.302326  "
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  rating  unix_timestamp\n",
       "movie_id                                 \n",
       "1             452     452             452\n",
       "2             131     131             131\n",
       "3              90      90              90\n",
       "4             209     209             209\n",
       "5              86      86              86"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_ratings_count = movie_ratings.count()\n",
    "movie_ratings_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index of the movies df to be the same as ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title release_date  video_release_date  \\\n",
       "movie_id                                                       \n",
       "1          Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2          GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3         Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4         Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5            Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   imdb_url  \n",
       "movie_id                                                     \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...  \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...  \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...  \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...  \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.set_index(\"movie_id\", inplace=True)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Toy%20Story%2...</td>\n",
       "      <td>3.878319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?GoldenEye%20(...</td>\n",
       "      <td>3.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Four%20Rooms%...</td>\n",
       "      <td>3.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Get%20Shorty%...</td>\n",
       "      <td>3.550239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>01-Jan-1995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Copycat%20(1995)</td>\n",
       "      <td>3.302326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      title release_date  video_release_date  \\\n",
       "movie_id                                                       \n",
       "1          Toy Story (1995)  01-Jan-1995                 NaN   \n",
       "2          GoldenEye (1995)  01-Jan-1995                 NaN   \n",
       "3         Four Rooms (1995)  01-Jan-1995                 NaN   \n",
       "4         Get Shorty (1995)  01-Jan-1995                 NaN   \n",
       "5            Copycat (1995)  01-Jan-1995                 NaN   \n",
       "\n",
       "                                                   imdb_url   ratings  \n",
       "movie_id                                                               \n",
       "1         http://us.imdb.com/M/title-exact?Toy%20Story%2...  3.878319  \n",
       "2         http://us.imdb.com/M/title-exact?GoldenEye%20(...  3.206107  \n",
       "3         http://us.imdb.com/M/title-exact?Four%20Rooms%...  3.033333  \n",
       "4         http://us.imdb.com/M/title-exact?Get%20Shorty%...  3.550239  \n",
       "5         http://us.imdb.com/M/title-exact?Copycat%20(1995)  3.302326  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## average and combine\n",
    "# the ratings are averages above for each movie id. now to make a ratings column in the movies df\n",
    "t = movies\n",
    "t[\"ratings\"] = movie_ratings_mean[\"rating\"]\n",
    "t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max movie rating 5.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>video_release_date</th>\n",
       "      <th>imdb_url</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>Great Day in Harlem, A (1994)</td>\n",
       "      <td>01-Jan-1994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Great%20Day%2...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>They Made Me a Criminal (1939)</td>\n",
       "      <td>01-Jan-1939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?They%20Made%2...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>Prefontaine (1997)</td>\n",
       "      <td>24-Jan-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Prefontaine%2...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>Marlene Dietrich: Shadow and Light (1996)</td>\n",
       "      <td>02-Apr-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Marlene%20Die...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Star Kid (1997)</td>\n",
       "      <td>16-Jan-1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?imdb-title-12...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Saint of Fort Washington, The (1993)</td>\n",
       "      <td>01-Jan-1993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Saint%20of%20...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>Santa with Muscles (1996)</td>\n",
       "      <td>08-Nov-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Santa%20with%...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>Aiqing wansui (1994)</td>\n",
       "      <td>22-Jul-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Aiqing%20Wans...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Someone Else's America (1995)</td>\n",
       "      <td>10-May-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Someone%20Els...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>Entertaining Angels: The Dorothy Day Story (1996)</td>\n",
       "      <td>27-Sep-1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://us.imdb.com/M/title-exact?Entertaining%...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      title release_date  \\\n",
       "movie_id                                                                   \n",
       "814                           Great Day in Harlem, A (1994)  01-Jan-1994   \n",
       "1122                         They Made Me a Criminal (1939)  01-Jan-1939   \n",
       "1189                                     Prefontaine (1997)  24-Jan-1997   \n",
       "1201             Marlene Dietrich: Shadow and Light (1996)   02-Apr-1996   \n",
       "1293                                        Star Kid (1997)  16-Jan-1998   \n",
       "1467                   Saint of Fort Washington, The (1993)  01-Jan-1993   \n",
       "1500                              Santa with Muscles (1996)  08-Nov-1996   \n",
       "1536                                   Aiqing wansui (1994)  22-Jul-1996   \n",
       "1599                          Someone Else's America (1995)  10-May-1996   \n",
       "1653      Entertaining Angels: The Dorothy Day Story (1996)  27-Sep-1996   \n",
       "\n",
       "          video_release_date  \\\n",
       "movie_id                       \n",
       "814                      NaN   \n",
       "1122                     NaN   \n",
       "1189                     NaN   \n",
       "1201                     NaN   \n",
       "1293                     NaN   \n",
       "1467                     NaN   \n",
       "1500                     NaN   \n",
       "1536                     NaN   \n",
       "1599                     NaN   \n",
       "1653                     NaN   \n",
       "\n",
       "                                                   imdb_url  ratings  \n",
       "movie_id                                                              \n",
       "814       http://us.imdb.com/M/title-exact?Great%20Day%2...      5.0  \n",
       "1122      http://us.imdb.com/M/title-exact?They%20Made%2...      5.0  \n",
       "1189      http://us.imdb.com/M/title-exact?Prefontaine%2...      5.0  \n",
       "1201      http://us.imdb.com/M/title-exact?Marlene%20Die...      5.0  \n",
       "1293      http://us.imdb.com/M/title-exact?imdb-title-12...      5.0  \n",
       "1467      http://us.imdb.com/M/title-exact?Saint%20of%20...      5.0  \n",
       "1500      http://us.imdb.com/M/title-exact?Santa%20with%...      5.0  \n",
       "1536      http://us.imdb.com/M/title-exact?Aiqing%20Wans...      5.0  \n",
       "1599      http://us.imdb.com/M/title-exact?Someone%20Els...      5.0  \n",
       "1653      http://us.imdb.com/M/title-exact?Entertaining%...      5.0  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the maximum rating\n",
    "# your code here\n",
    "print(\"max movie rating\", t[\"ratings\"].max())\n",
    "\n",
    "# get movie ids with that rating\n",
    "# your code here\n",
    "t[t[\"ratings\"]>=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good movie ids:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Int64Index([  12,   22,   23,   45,   48,   50,   56,   59,   60,   64,\n",
       "            ...\n",
       "            1449, 1467, 1500, 1524, 1536, 1594, 1599, 1639, 1642, 1653],\n",
       "           dtype='int64', name='movie_id', length=132)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Good movie ids:\")\n",
    "movies[movies[\"ratings\"]>4].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best movie titles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "814                         Great Day in Harlem, A (1994)\n",
       "1122                       They Made Me a Criminal (1939)\n",
       "1189                                   Prefontaine (1997)\n",
       "1201           Marlene Dietrich: Shadow and Light (1996) \n",
       "1293                                      Star Kid (1997)\n",
       "1467                 Saint of Fort Washington, The (1993)\n",
       "1500                            Santa with Muscles (1996)\n",
       "1536                                 Aiqing wansui (1994)\n",
       "1599                        Someone Else's America (1995)\n",
       "1653    Entertaining Angels: The Dorothy Day Story (1996)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best movie titles:\")\n",
    "movies[movies[\"ratings\"]>4.99][\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id\n",
       "1    452\n",
       "2    131\n",
       "3     90\n",
       "4    209\n",
       "5     86\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of ratings per movie\n",
    "# your code here\n",
    "movie_ratings_count[\"rating\"].head()\n",
    "\n",
    "\n",
    "#print \"Number of ratings per movie\"\n",
    "#print # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Passing a Function\n",
    "==================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>3.610294</td>\n",
       "      <td>8.773916e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>249.500000</td>\n",
       "      <td>3.709677</td>\n",
       "      <td>8.886204e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>318.814815</td>\n",
       "      <td>2.796296</td>\n",
       "      <td>8.892372e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>291.041667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>8.920028e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>291.291429</td>\n",
       "      <td>2.874286</td>\n",
       "      <td>8.762081e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id    movie_id    rating  unix_timestamp\n",
       "user_id                                               \n",
       "1            1.0  136.500000  3.610294    8.773916e+08\n",
       "2            2.0  249.500000  3.709677    8.886204e+08\n",
       "3            3.0  318.814815  2.796296    8.892372e+08\n",
       "4            4.0  291.041667  4.333333    8.920028e+08\n",
       "5            5.0  291.291429  2.874286    8.762081e+08"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_ratings = grouped_data.apply(lambda f: f.mean())\n",
    "average_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz\n",
    "====\n",
    "\n",
    "* get the average rating per user\n",
    "* advanced: list all occupations and if they are male or female dominant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.500000</td>\n",
       "      <td>3.610294</td>\n",
       "      <td>8.773916e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>249.500000</td>\n",
       "      <td>3.709677</td>\n",
       "      <td>8.886204e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318.814815</td>\n",
       "      <td>2.796296</td>\n",
       "      <td>8.892372e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291.041667</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>8.920028e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>291.291429</td>\n",
       "      <td>2.874286</td>\n",
       "      <td>8.762081e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_id    rating  unix_timestamp\n",
       "user_id                                      \n",
       "1        136.500000  3.610294    8.773916e+08\n",
       "2        249.500000  3.709677    8.886204e+08\n",
       "3        318.814815  2.796296    8.892372e+08\n",
       "4        291.041667  4.333333    8.920028e+08\n",
       "5        291.291429  2.874286    8.762081e+08"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the average rating per user\n",
    "# your code here\n",
    "user_ratings = ratings.groupby(\"user_id\")\n",
    "user_ratings.mean().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'writer', 'retired', 'doctor', 'programmer', 'scientist', 'other', 'homemaker', 'salesman', 'marketing', 'none', 'student', 'healthcare', 'educator', 'engineer', 'administrator', 'technician', 'entertainment', 'executive', 'artist', 'librarian', 'lawyer'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>administrator</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>artist</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educator</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineer</th>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>executive</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthcare</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homemaker</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lawyer</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>librarian</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marketing</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>none</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>programmer</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salesman</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scientist</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>writer</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id  age  sex  zip_code\n",
       "occupation                                \n",
       "administrator       43   43   43        43\n",
       "artist              15   15   15        15\n",
       "doctor               7    7    7         7\n",
       "educator            69   69   69        69\n",
       "engineer            65   65   65        65\n",
       "entertainment       16   16   16        16\n",
       "executive           29   29   29        29\n",
       "healthcare           5    5    5         5\n",
       "homemaker            1    1    1         1\n",
       "lawyer              10   10   10        10\n",
       "librarian           22   22   22        22\n",
       "marketing           16   16   16        16\n",
       "none                 5    5    5         5\n",
       "other               69   69   69        69\n",
       "programmer          60   60   60        60\n",
       "retired             13   13   13        13\n",
       "salesman             9    9    9         9\n",
       "scientist           28   28   28        28\n",
       "student            136  136  136       136\n",
       "technician          26   26   26        26\n",
       "writer              26   26   26        26"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all occupations and if they are male or female dominant\n",
    "# your code here\n",
    "print(set(users[\"occupation\"].values))\n",
    "\n",
    "male = users[users[\"sex\"]==\"M\"].groupby(\"occupation\").count()\n",
    "female = users[users[\"sex\"]==\"F\"].groupby(\"occupation\").count()\n",
    "male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "administrator     43\n",
       "artist            15\n",
       "doctor             7\n",
       "educator          69\n",
       "engineer          65\n",
       "entertainment     16\n",
       "executive         29\n",
       "healthcare         5\n",
       "homemaker          1\n",
       "lawyer            10\n",
       "librarian         22\n",
       "marketing         16\n",
       "none               5\n",
       "other             69\n",
       "programmer        60\n",
       "retired           13\n",
       "salesman           9\n",
       "scientist         28\n",
       "student          136\n",
       "technician        26\n",
       "writer            26\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['sex'].groupby(users['occupation']).apply(lambda f: sum(f==\"M\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "occupation\n",
       "administrator     True\n",
       "artist            True\n",
       "doctor            True\n",
       "educator          True\n",
       "engineer          True\n",
       "entertainment     True\n",
       "executive         True\n",
       "healthcare       False\n",
       "homemaker        False\n",
       "lawyer            True\n",
       "librarian        False\n",
       "marketing         True\n",
       "none              True\n",
       "other             True\n",
       "programmer        True\n",
       "retired           True\n",
       "salesman          True\n",
       "scientist         True\n",
       "student           True\n",
       "technician        True\n",
       "writer            True\n",
       "Name: sex, dtype: bool"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data = users['sex'].groupby(users['occupation'])\n",
    "male_dominant_occupations = grouped_data.apply(lambda f: \n",
    "                                               sum(f == 'M') > sum(f == 'F'))\n",
    "male_dominant_occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(670, 273)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#'number of male and female users: '\n",
    "sum(users['sex'] == 'M'), sum(users['sex'] == 'F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Pandas \"wrapup\"\n",
    "==========\n",
    "\n",
    "- create data frames\n",
    "- get sub-frames\n",
    "- filter data \n",
    "- use group-by\n",
    "- apply a user defined function\n",
    "\n",
    "\n",
    "![cute panda](images/cute_panda.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python data scraping\n",
    "====================\n",
    "\n",
    "* Why scrape the web?\n",
    "    - vast source of information\n",
    "    - automate tasks\n",
    "    - keep up with sites\n",
    "    - fun!\n",
    "\n",
    "** Can you think of examples ? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read and Tweet!\n",
    "=================\n",
    "\n",
    "![ReadTweet](http://developer.nytimes.com/files/readtweet.jpg)\n",
    "\n",
    "* by Justin Blinder\n",
    "* http://projects.justinblinder.com/We-Read-We-Tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "“We Read, We Tweet” geographically visualizes the dissemination of New York Times articles through Twitter. Each line connects the location of a tweet to the contextual location of the New York Times article it referenced. The lines are generated in a sequence based on the time in which a tweet occurs. The project explores digital news distribution in a temporal and spatial context through the social space of Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Twitter Sentiments\n",
    "=================\n",
    "\n",
    "![TwitterSentiments](http://www.csc.ncsu.edu/faculty/healey/tweet_viz/figs/tweet-viz-ex.png\n",
    " \"Twitter Sentiments\")\n",
    "\n",
    "* by Healey and Ramaswamy\n",
    "* http://www.csc.ncsu.edu/faculty/healey/tweet_viz/tweet_app/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Type a keyword into the input field, then click the Query button. Recent tweets that contain your keyword are pulled from Twitter and visualized in the Sentiment tab as circles. Hover your mouse over a tweet or click on it to see its text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python data scraping\n",
    "====================\n",
    "\n",
    "* copyrights and permission:\n",
    "    - be careful and polite\n",
    "    - give credit\n",
    "    - care about media law\n",
    "    - don't be evil (no spam, overloading sites, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Robots.txt\n",
    "==========\n",
    "\n",
    "![Robots.txt](images/robots_txt.jpg \"Robots.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Robots.txt\n",
    "==========\n",
    "\n",
    "* specified by web site owner\n",
    "* gives instructions to web robots (aka your script)\n",
    "* is located at the top-level directory of the web server\n",
    "\n",
    "http://www.example.com/robots.txt\n",
    "\n",
    "If you want you can also have a look at\n",
    "\n",
    "http://google.com/robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Robots.txt\n",
    "==========\n",
    "\n",
    "*** What does this one do? ***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "User-agent: Google\n",
    "Disallow:\n",
    "\n",
    "User-agent: *\n",
    "Disallow: /"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Things to consider:\n",
    "-------------------\n",
    "\n",
    "* can be just ignored\n",
    "* can be a security risk - *** Why? ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping with Python:\n",
    "=====================\n",
    "\n",
    "* scraping is all about HTML tags\n",
    "* bad news: \n",
    "    - need to learn about tags\n",
    "    - websites can be ugly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "HTML\n",
    "=====\n",
    "\n",
    "* HyperText Markup Language\n",
    "\n",
    "* standard for creating webpages\n",
    "\n",
    "* HTML tags \n",
    "    - have angle brackets\n",
    "    - typically come in pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This is an example for a minimal webpage defined in HTML tags. The root tag is `<html>` and then you have the `<head>` tag. This part of the page typically includes the title of the page and might also have other meta information like the author or keywords that are important for search engines. The `<body>` tag marks the actual content of the page. You can play around with the `<h2>` tag trying different header levels. They range from 1 to 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "htmlString = \"\"\"<!DOCTYPE html>\n",
    "<html>\n",
    "  <head>\n",
    "    <title>This is a title</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h2> Test </h2>\n",
    "    <p>Hello world!</p>\n",
    "  </body>\n",
    "</html>\"\"\"\n",
    "\n",
    "htmlOutput = HTML(htmlString)\n",
    "htmlOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Useful Tags\n",
    "===========\n",
    "\n",
    "* heading\n",
    "`<h1></h1> ... <h6></h6>`\n",
    "\n",
    "* paragraph\n",
    "`<p></p>` \n",
    "\n",
    "* line break\n",
    "`<br>` \n",
    "\n",
    "* link with attribute\n",
    "\n",
    "`<a href=\"http://www.example.com/\">An example link</a>`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping with Python:\n",
    "=====================\n",
    "\n",
    "* example of a beautifully simple webpage:\n",
    "\n",
    "http://www.crummy.com/software/BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping with Python:\n",
    "=====================\n",
    "\n",
    "* good news: \n",
    "    - some browsers help\n",
    "    - look for: inspect element\n",
    "    - need only basic html\n",
    "    \n",
    "** Try 'Ctrl-Shift I' in Chrome **\n",
    "\n",
    "** Try 'Command-Option I' in Safari **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping with Python\n",
    "==================\n",
    "\n",
    "* different useful libraries:\n",
    "    - urllib\n",
    "    - beautifulsoup\n",
    "    - pattern\n",
    "    - soupy\n",
    "    - LXML\n",
    "    - ...\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following cell just defines a url as a string and then reads the data from that url using the `urllib` library. If you uncomment the print command you see that we got the whole HTML content of the page into the string variable source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\"\\n\"http://www.w3.org/TR/REC-html40/transitional.dtd\">\\n<html>\\n<head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\\n<title>Beautiful Soup: We called him Tortoise because he taught us.</title>\\n<link rev=\"made\" href=\"mailto:leonardr@segfault.org\">\\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/nb/themes/Default/nb.css\">\\n<meta name=\"Description\" content=\"Beautiful Soup: a library designed for screen-scraping HTML and XML.\">\\n<meta name=\"generator\" content=\"Markov Approximation 1.4 (module: leonardr)\">\\n<meta name=\"author\" content=\"Leonard Richardson\">\\n</head>\\n<body bgcolor=\"white\" text=\"black\" link=\"blue\" vlink=\"660066\" alink=\"red\">\\n<img align=\"right\" src=\"10.1.jpg\" width=\"250\"><br />\\n\\n<p>You didn\\'t write that awful page. You\\'re just trying to get some\\ndata out of it. Beautiful Soup is here to help. Since 2004, it\\'s been\\nsaving programmers hours or days of work on quick-turnaround\\nscreen scraping projects.</p>\\n\\n<div align=\"center\">\\n\\n<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>\\n\\n<p>\"A tremendous boon.\" -- Python411 Podcast</p>\\n\\n<p>[ <a href=\"#Download\">Download</a> | <a\\nhref=\"bs4/doc/\">Documentation</a> | <a href=\"#HallOfFame\">Hall of Fame</a> | <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a> | <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a> ]</p>\\n\\n<small>If Beautiful Soup has saved you a lot of time and money, one way to pay me back is to check out <a\\nhref=\"http://www.candlemarkandgleam.com/shop/constellation-games/\"><i>Constellation\\nGames</i>, my sci-fi novel about alien video games</a>.<br />You can\\n<a\\nhref=\"http://constellation.crummy.com/Constellation%20Games%20excerpt.html\">read\\nthe first two chapters for free</a>, and the full novel starts at 5\\nUSD. Thanks!</small> </div>\\n\\n<p><i>If you have questions, send them to <a\\nhref=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\\ngroup</a>. If you find a bug, <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it</a>.</i></p>\\n\\n<p>Beautiful Soup is a Python library designed for quick turnaround\\nprojects like screen-scraping. Three features make it powerful:\\n\\n<ol>\\n\\n<li>Beautiful Soup provides a few simple methods and Pythonic idioms\\nfor navigating, searching, and modifying a parse tree: a toolkit for\\ndissecting a document and extracting what you need. It doesn\\'t take\\nmuch code to write an application\\n\\n<li>Beautiful Soup automatically converts incoming documents to\\nUnicode and outgoing documents to UTF-8. You don\\'t have to think\\nabout encodings, unless the document doesn\\'t specify an encoding and\\nBeautiful Soup can\\'t detect one. Then you just have to specify the\\noriginal encoding.\\n\\n<li>Beautiful Soup sits on top of popular Python parsers like <a\\nhref=\"http://lxml.de/\">lxml</a> and <a\\nhref=\"http://code.google.com/p/html5lib/\">html5lib</a>, allowing you\\nto try out different parsing strategies or trade speed for\\nflexibility.\\n\\n</ol>\\n\\n<p>Beautiful Soup parses anything you give it, and does the tree\\ntraversal stuff for you. You can tell it \"Find all the links\", or\\n\"Find all the links of class <tt>externalLink</tt>\", or \"Find all the\\nlinks whose urls match \"foo.com\", or \"Find the table heading that\\'s\\ngot bold text, then give me that text.\"\\n\\n<p>Valuable data that was once locked up in poorly-designed websites\\nis now within your reach. Projects that would have taken hours take\\nonly minutes with Beautiful Soup.\\n\\n<p>Interested? <a href=\"bs4/doc/\">Read more.</a>\\n\\n<a name=\"Download\"><h2>Download Beautiful Soup</h2></a>\\n\\n<p>The current release is <a href=\"bs4/download/\">Beautiful Soup\\n4.6.0</a> (May 7, 2017). You can install Beautiful Soup 4 with\\n<code>pip install beautifulsoup4</code>.\\n\\n<p>In Debian and Ubuntu, Beautiful Soup is available as the\\n<code>python-bs4</code> package (for Python 2) or the\\n<code>python3-bs4</code> package (for Python 3). In Fedora it\\'s\\navailable as the <code>python-beautifulsoup4</code> package.\\n\\n<p>Beautiful Soup is licensed under the MIT license, so you can also\\ndownload the tarball, drop the <code>bs4/</code> directory into almost\\nany Python application (or into your library path) and start using it\\nimmediately. (If you want to do this under Python 3, you will need to\\nmanually convert the code using <code>2to3</code>.)\\n\\n<p>Beautiful Soup 4 works on both Python 2 (2.7+) and Python 3.\\n\\n<h3>Beautiful Soup 3</h3>\\n\\n<p>Beautiful Soup 3 was the official release line of Beautiful Soup\\nfrom May 2006 to March 2012. It is considered stable, and only\\ncritical security bugs will be fixed. <a\\nhref=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here\\'s\\nthe Beautiful Soup 3 documentation.</a>\\n\\n<p>Beautiful Soup 3 works only under Python 2.x. It is licensed under\\nthe same license as Python itself.\\n\\n<p>The current release of Beautiful Soup 3 is <a\\nhref=\"download/3.x/BeautifulSoup-3.2.1.tar.gz\">3.2.1</a> (February 16,\\n2012). You can install Beautiful Soup 3 with <code>pip install\\nBeautifulSoup</code>. It\\'s also available as\\n<code>python-beautifulsoup</code> in Debian and Ubuntu, and as\\n<code>python-BeautifulSoup</code> in Fedora.\\n\\n<p>You can also download the tarball and use\\n<code>BeautifulSoup.py</code> in your project directly.\\n\\n\\n<a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>\\n\\n<p>Over the years, Beautiful Soup has been used in hundreds of\\ndifferent projects. There\\'s no way I can list them all, but I want to\\nhighlight a few high-profile projects. Beautiful Soup isn\\'t what makes\\nthese projects interesting, but it did make their completion easier:\\n\\n<ul>\\n\\n<li><a\\n href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\\n Type\"</a>, a work of digital art on display in the lobby of the New\\n York Times building, uses Beautiful Soup to scrape news feeds.\\n\\n<li>Reddit uses Beautiful Soup to <a\\nhref=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\\na page that\\'s been linked to and find a representative image</a>.\\n\\n<li>Alexander Harrowell uses Beautiful Soup to <a\\n href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\\n activities</a> of an arms merchant.\\n\\n<li>The developers of Python itself used Beautiful Soup to <a\\nhref=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\\nbug tracker from Sourceforge to Roundup</a>.\\n\\n<li>The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\\nuses Beautiful Soup to <A\\nhref=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\\nstatewide election results</a>.\\n\\n<li>The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA\\'s Forecast\\nApplications Branch</a> uses Beautiful Soup in <a\\nhref=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\\ndownloading \"high resolution USGS datasets.\"\\n\\n</ul>\\n\\n<p>If you\\'ve used Beautiful Soup in a project you\\'d like me to know\\nabout, please do send email to me or <a\\nhref=\"http://groups.google.com/group/beautifulsoup/\">the discussion\\ngroup</a>.\\n\\n<h2>Development</h2>\\n\\n<p>Development happens at <a\\nhref=\"https://launchpad.net/beautifulsoup\">Launchpad</a>. You can <a\\nhref=\"https://code.launchpad.net/beautifulsoup/\">get the source\\ncode</a> or <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\\nbugs</a>.<hr><table><tr><td valign=\"top\">\\n<p>This document (<a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>) is part of Crummy, the webspace of <a href=\"/self/\">Leonard Richardson</a> (<a href=\"/self/contact.html\">contact information</a>). It was last modified on Friday, May 19 2017, 22:10:19 Nowhere Standard Time and last built on Monday, August 07 2017, 04:00:02 Nowhere Standard Time.</p><p><table class=\"licenseText\"><tr><td><a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"></a></td><td valign=\"top\">Crummy is &copy; 1996-2017 Leonard Richardson. Unless otherwise noted, all text licensed under a <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>.</td></tr></table></span><!--<rdf:RDF xmlns=\"http://web.resource.org/cc/\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"><Work rdf:about=\"http://www.crummy.com/\"><dc:title>Crummy: The Site</dc:title><dc:rights><Agent><dc:title>Crummy: the Site</dc:title></Agent></dc:rights><dc:format>text/html</dc:format><license rdf:resource=http://creativecommons.org/licenses/by-sa/2.0//></Work><License rdf:about=\"http://creativecommons.org/licenses/by-sa/2.0/\"></License></rdf:RDF>--></p></td><td valign=top><p><b>Document tree:</b>\\n<dl><dd><a href=\"http://www.crummy.com/\">http://www.crummy.com/</a><dl><dd><a href=\"http://www.crummy.com/software/\">software/</a><dl><dd><a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a></dl>\\n</dl>\\n</dl>\\n\\n\\nSite Search:\\n\\n<form method=\"get\" action=\"/search/\">\\n        <input type=\"text\" name=\"q\" maxlength=\"255\" value=\"\"></input>\\n        </form>\\n        </td>\\n\\n</tr>\\n\\n</table>\\n</body>\\n</html>\\n'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://www.crummy.com/software/BeautifulSoup'\n",
    "source = urllib.request.urlopen(url).read()\n",
    "source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz :\n",
    "======\n",
    "\n",
    "* Is the word 'Alice' mentioned on the beautiful soup homepage?\n",
    "* How often does the word 'Soup' occur on the site?\n",
    "    - hint: use `.count()`\n",
    "* At what index occurs the substring 'alien video games' ?\n",
    "    - hint: use `.find()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Soup count: 42\n",
      "1634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'alien vide'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## is 'Alice' in source?\n",
    "print(source.count(b\"Alice\"))\n",
    "## count occurences of 'Soup'\n",
    "print(\"Soup count:\" ,source.count(b\"Soup\"))\n",
    "## find index of 'alien video games'\n",
    "print(source.index(b'alien video games'))\n",
    "source[1634:1644]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Beautiful Soup\n",
    "==============\n",
    "\n",
    "* designed to make your life easier\n",
    "* many good functions for parsing html code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some examples\n",
    "=============\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ko/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ko/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<a href=\"bs4/download/\"><h1>Beautiful Soup</h1></a>,\n",
       " <a href=\"#Download\">Download</a>,\n",
       " <a href=\"bs4/doc/\">Documentation</a>,\n",
       " <a href=\"#HallOfFame\">Hall of Fame</a>,\n",
       " <a href=\"https://code.launchpad.net/beautifulsoup\">Source</a>,\n",
       " <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">Discussion group</a>,\n",
       " <a href=\"http://www.candlemarkandgleam.com/shop/constellation-games/\"><i>Constellation\n",
       " Games</i>, my sci-fi novel about alien video games</a>,\n",
       " <a href=\"http://constellation.crummy.com/Constellation%20Games%20excerpt.html\">read\n",
       " the first two chapters for free</a>,\n",
       " <a href=\"https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup\">the discussion\n",
       " group</a>,\n",
       " <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file it</a>,\n",
       " <a href=\"http://lxml.de/\">lxml</a>,\n",
       " <a href=\"http://code.google.com/p/html5lib/\">html5lib</a>,\n",
       " <a href=\"bs4/doc/\">Read more.</a>,\n",
       " <a name=\"Download\"><h2>Download Beautiful Soup</h2></a>,\n",
       " <a href=\"bs4/download/\">Beautiful Soup\n",
       " 4.6.0</a>,\n",
       " <a href=\"http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html\">Here's\n",
       " the Beautiful Soup 3 documentation.</a>,\n",
       " <a href=\"download/3.x/BeautifulSoup-3.2.1.tar.gz\">3.2.1</a>,\n",
       " <a name=\"HallOfFame\"><h2>Hall of Fame</h2></a>,\n",
       " <a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       "  Type\"</a>,\n",
       " <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       " a page that's been linked to and find a representative image</a>,\n",
       " <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
       "  activities</a>,\n",
       " <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
       " bug tracker from Sourceforge to Roundup</a>,\n",
       " <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>,\n",
       " <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
       " statewide election results</a>,\n",
       " <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
       " Applications Branch</a>,\n",
       " <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>,\n",
       " <a href=\"http://groups.google.com/group/beautifulsoup/\">the discussion\n",
       " group</a>,\n",
       " <a href=\"https://launchpad.net/beautifulsoup\">Launchpad</a>,\n",
       " <a href=\"https://code.launchpad.net/beautifulsoup/\">get the source\n",
       " code</a>,\n",
       " <a href=\"https://bugs.launchpad.net/beautifulsoup/\">file\n",
       " bugs</a>,\n",
       " <a href=\"/source/software/BeautifulSoup/index.bhtml\">source</a>,\n",
       " <a href=\"/self/\">Leonard Richardson</a>,\n",
       " <a href=\"/self/contact.html\">contact information</a>,\n",
       " <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\"><img border=\"0\" src=\"/nb//resources/img/somerights20.jpg\"/></a>,\n",
       " <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Creative Commons License</a>,\n",
       " <a href=\"http://www.crummy.com/\">http://www.crummy.com/</a>,\n",
       " <a href=\"http://www.crummy.com/software/\">software/</a>,\n",
       " <a href=\"http://www.crummy.com/software/BeautifulSoup/\">BeautifulSoup/</a>]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get bs4 object\n",
    "soup = bs4.BeautifulSoup(source)\n",
    " \n",
    "## compare the two print statements\n",
    "#print soup\n",
    "#print soup.prettify()\n",
    "\n",
    "## show how to find all a tags\n",
    "soup.findAll('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ***Why does this not work? ***\n",
    "soup.findAll('Soup')\n",
    "# findAll only searches tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some examples\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs4/download/',\n",
       " '#Download',\n",
       " 'bs4/doc/',\n",
       " '#HallOfFame',\n",
       " 'https://code.launchpad.net/beautifulsoup']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get attribute value from an element:\n",
    "## find tag: this only returns the first occurrence, not all tags in the string\n",
    "first_tag = soup.find('a')\n",
    "\n",
    "## get attribute `href`\n",
    "first_tag.get('href')\n",
    "\n",
    "## get all links in the page\n",
    "link_list = [l.get('href') for l in soup.findAll('a')]\n",
    "link_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-311-db28b6c7151c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# if it starts with 'http' we are happy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlink_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'http'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mexternal_links\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "## filter all external links\n",
    "# create an empty list to collect the valid links\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "\n",
    "# this throws an error! It says something about 'NoneType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bs4/download/',\n",
       " '#Download',\n",
       " 'bs4/doc/',\n",
       " '#HallOfFame',\n",
       " 'https://code.launchpad.net/beautifulsoup',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://www.candlemarkandgleam.com/shop/constellation-games/',\n",
       " 'http://constellation.crummy.com/Constellation%20Games%20excerpt.html',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'bs4/doc/',\n",
       " None,\n",
       " 'bs4/download/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'download/3.x/BeautifulSoup-3.2.1.tar.gz',\n",
       " None,\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " '/source/software/BeautifulSoup/index.bhtml',\n",
       " '/self/',\n",
       " '/self/contact.html',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets investigate. Have a close look at the link_list:\n",
    "link_list\n",
    "\n",
    "# Seems that there are None elements!\n",
    "# Let's verify\n",
    "#print sum([l is None for l in link_list])\n",
    "\n",
    "# So there are two elements in the list that are None!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://www.candlemarkandgleam.com/shop/constellation-games/',\n",
       " 'http://constellation.crummy.com/Constellation%20Games%20excerpt.html',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's filter those objects out in the for loop\n",
    "external_links = []\n",
    "\n",
    "# write a loop to filter the links\n",
    "# if it is not None and starts with 'http' we are happy\n",
    "for l in link_list:\n",
    "    if l is not None and l[:4] == 'http':\n",
    "        external_links.append(l)\n",
    "        \n",
    "external_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Note: The above `if` condition works because of lazy evaluation in Python. The `and` statement becomes `False` if the first part is `False`, so there is no need to ever evaluate the second part. Thus a `None` entry in the list gets never asked about its first four characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://code.launchpad.net/beautifulsoup',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'http://www.candlemarkandgleam.com/shop/constellation-games/',\n",
       " 'http://constellation.crummy.com/Constellation%20Games%20excerpt.html',\n",
       " 'https://groups.google.com/forum/?fromgroups#!forum/beautifulsoup',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://lxml.de/',\n",
       " 'http://code.google.com/p/html5lib/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/bs3/documentation.html',\n",
       " 'http://www.nytimes.com/2007/10/25/arts/design/25vide.html',\n",
       " 'https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py',\n",
       " 'http://www.harrowell.org.uk/viktormap.html',\n",
       " 'http://svn.python.org/view/tracker/importer/',\n",
       " 'http://www2.ljworld.com/',\n",
       " 'http://www.b-list.org/weblog/2010/nov/02/news-done-broke/',\n",
       " 'http://esrl.noaa.gov/gsd/fab/',\n",
       " 'http://laps.noaa.gov/topograbber/',\n",
       " 'http://groups.google.com/group/beautifulsoup/',\n",
       " 'https://launchpad.net/beautifulsoup',\n",
       " 'https://code.launchpad.net/beautifulsoup/',\n",
       " 'https://bugs.launchpad.net/beautifulsoup/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       " 'http://www.crummy.com/',\n",
       " 'http://www.crummy.com/software/',\n",
       " 'http://www.crummy.com/software/BeautifulSoup/']"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and we can put this in a list comprehension as well, it almost reads like \n",
    "# a sentence.\n",
    "\n",
    "[l for l in link_list if l is not None and l.startswith('http')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Parsing the Tree\n",
    "================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ko/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/ko/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<body><h3> Test </h3><p>Hello world!</p></body>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# redifining `s` without any line breaks\n",
    "s = \"\"\"<!DOCTYPE html><html><head><title>This is a title</title></head><body><h3> Test </h3><p>Hello world!</p></body></html>\"\"\"\n",
    "## get bs4 object\n",
    "tree = bs4.BeautifulSoup(s)\n",
    "\n",
    "## get html root node\n",
    "root_node = tree.html\n",
    "\n",
    "## get head from root using contents\n",
    "head = root_node.contents[0]\n",
    "\n",
    "## get body from root\n",
    "body = root_node.contents[1]\n",
    "\n",
    "## could directly access body\n",
    "tree.body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz:\n",
    "=====\n",
    "\n",
    "* Find the `h3` tag by parsing the tree starting at `body`\n",
    "* Create a list of all __Hall of Fame__ entries listed on the Beautiful Soup webpage\n",
    "    - hint: it is the only unordered list in the page (tag `ul`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h3> Test </h3>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## get h3 tag from body\n",
    "tree.body.find(\"h3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
       "   Type\"</a>,\n",
       "  ', a work of digital art on display in the lobby of the New\\n York Times building, uses Beautiful Soup to scrape news feeds.\\n\\n'],\n",
       " ['Reddit uses Beautiful Soup to ',\n",
       "  <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
       "  a page that's been linked to and find a representative image</a>,\n",
       "  '.\\n\\n']]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use ul as entry point\n",
    "\n",
    "h = soup.find(\"ul\")\n",
    "\n",
    "## get hall of fame list from entry point\n",
    "## skip the first entry \n",
    "\n",
    "## reformat into a list containing strings\n",
    "## it is ok to have a list of lists\n",
    "\n",
    "hall = [entry.contents for entry in h.contents[1:]]\n",
    "hall[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`tmp` now is actually a list of lists containing the hall of fame entries. \n",
    "Here is some advanced Python on how to print really just one entry per list item.\n",
    "\n",
    "The cool things about this are: \n",
    "* The use of `\"\"` to just access the `join` function of strings.\n",
    "* The `join` function itself\n",
    "* that you can actually have two nested for loops in a list comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://www.nytimes.com/2007/10/25/arts/design/25vide.html\">\"Movable\n",
      " Type\"</a>, a work of digital art on display in the lobby of the New\n",
      " York Times building, uses Beautiful Soup to scrape news feeds.\n",
      "\n",
      "\n",
      "Reddit uses Beautiful Soup to <a href=\"https://github.com/reddit/reddit/blob/85f9cff3e2ab9bb8f19b96acd8da4ebacc079f04/r2/r2/lib/media.py\">parse\n",
      "a page that's been linked to and find a representative image</a>.\n",
      "\n",
      "\n",
      "Alexander Harrowell uses Beautiful Soup to <a href=\"http://www.harrowell.org.uk/viktormap.html\">track the business\n",
      " activities</a> of an arms merchant.\n",
      "\n",
      "\n",
      "The developers of Python itself used Beautiful Soup to <a href=\"http://svn.python.org/view/tracker/importer/\">migrate the Python\n",
      "bug tracker from Sourceforge to Roundup</a>.\n",
      "\n",
      "\n",
      "The <a href=\"http://www2.ljworld.com/\">Lawrence Journal-World</a>\n",
      "uses Beautiful Soup to <a href=\"http://www.b-list.org/weblog/2010/nov/02/news-done-broke/\">gather\n",
      "statewide election results</a>.\n",
      "\n",
      "\n",
      "The <a href=\"http://esrl.noaa.gov/gsd/fab/\">NOAA's Forecast\n",
      "Applications Branch</a> uses Beautiful Soup in <a href=\"http://laps.noaa.gov/topograbber/\">TopoGrabber</a>, a script for\n",
      "downloading \"high resolution USGS datasets.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test =  [\"\".join(str(a) for a in sublist) for sublist in hall]\n",
    "print('\\n'.join(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Advanced Example\n",
    "===============\n",
    "\n",
    "Idea by [Jesse Steinweg-Woods](https://jessesw.com/Data-Science-Skills/)\n",
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping data science skills\n",
    "=============================\n",
    "\n",
    "- What skills are in demand for data scientists?\n",
    "- Should we have a lecture on Spark or only on MapReduce?\n",
    "\n",
    "We want to scrape the information from job advertisements for data scientists from indeed.com\n",
    "Let's scrape and find out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Fixed url for job postings containing data scientist\n",
    "url = 'http://www.indeed.com.au/jobs?q=data+scientist&l='\n",
    "# read the website\n",
    "source = urllib.request.urlopen(url).read()\n",
    "# parse html code\n",
    "bs_tree = bs4.BeautifulSoup(source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search yielded 605 hits.\n"
     ]
    }
   ],
   "source": [
    "# see how many job postings we found\n",
    "job_count_string = bs_tree.find(id = \"searchCount\").contents[0]\n",
    "job_count_string = job_count_string.split()\n",
    "job_count_string=[s.replace(',','') for s in job_count_string]\n",
    "# print((job_count_string))\n",
    "\n",
    "# not that job_count so far is still a string, \n",
    "# not an integer, and the , separator prevents \n",
    "# us from just casting it to int\n",
    "\n",
    "job_count_digits = [int(d) for d in job_count_string if d.isdigit()]\n",
    "job_count = np.sum([digit*(10**exponent) for digit, exponent in \n",
    "                    zip(job_count_digits[::-1], range(len(job_count_digits)))])\n",
    "\n",
    "print(\"Search yielded %s hits.\" % (job_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remaining page num 1\n",
      "We found a lot of jobs:  10\n"
     ]
    }
   ],
   "source": [
    "# The website is only listing 10 results per page, \n",
    "# so we need to scrape them page after page\n",
    "num_pages = int(np.ceil(job_count/10.0))\n",
    "pages_where_to_stop=1;\n",
    "base_url = 'http://www.indeed.com'\n",
    "job_links = []\n",
    "for i in range(pages_where_to_stop): #do range(num_pages) if you want them all\n",
    "    \n",
    "    if i%10==0:\n",
    "        if i<10:\n",
    "            print(\"remaining page num\",pages_where_to_stop-i)\n",
    "        else:\n",
    "            print(\"remaining page num\", pages_where_to_stop-i)\n",
    "    url = 'http://www.indeed.com.au/jobs?q=data+scientist&start=' + str(i*10)\n",
    "    html_page = urllib.request.urlopen(url).read() \n",
    "    bs_tree = bs4.BeautifulSoup(html_page)\n",
    "    \n",
    "        \n",
    "    job_link_area = bs_tree.find(id = 'resultsCol')\n",
    "   \n",
    "    \n",
    "    job_postings = job_link_area.findAll(\"div\")\n",
    "    job_posting=[jp for jp in job_postings if   jp.get('class')=='jobsearch-SerpJobCard unifiedRow row result clickcard']\n",
    "   \n",
    "    job_ids = [jp.get('data-jk') for jp in job_postings if jp.get('data-jk') is not None]\n",
    "\n",
    " \n",
    "    # go after each link\n",
    "    for id in job_ids:\n",
    "        job_links.append(base_url + '/rc/clk?jk=' + id)\n",
    "\n",
    "    time.sleep(1)\n",
    "    \n",
    "print(\"We found a lot of jobs: \", len(job_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Some precautions to enable us to restart our search\n",
    "========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Save the scraped links\n",
    "with open('C:\\\\Users\\\\Seif\\\\OneDrive\\\\Documents\\\\cs209\\\\2015\\\\Lectures\\\\data\\\\scraped_links.pkl', 'wb') as f:\n",
    "    pickle.dump(job_links, f)\n",
    "    \n",
    "# Read canned scraped links\n",
    "with open('C:\\\\Users\\\\Seif\\\\OneDrive\\\\Documents\\\\cs209\\\\2015\\\\Lectures\\\\data\\\\scraped_links.pkl', 'rb') as f:\n",
    "    job_links = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "skill_set = {'mapreduce': 0, 'spark': 0}\n",
    "\n",
    "# write initialization into a file, so we can restart later\n",
    "with open('C:\\\\Users\\\\Seif\\\\OneDrive\\\\Documents\\\\cs209\\\\2015\\\\Lectures\\\\data\\\\scraped_links_restart.pkl', 'wb') as f:\n",
    "   pickle.dump((skill_set, 0),f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python Dictonaries\n",
    "==================\n",
    "\n",
    "* build in data type\n",
    "* uses key: value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2}\n",
      "dict_keys(['a', 'b'])\n",
      "dict_values([1, 2])\n",
      "a 1\n",
      "b 2\n",
      "---\n",
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "a = {'a': 1, 'b':2}\n",
    "print(a)\n",
    "\n",
    "#show keys\n",
    "print(a.keys())\n",
    "\n",
    "#show values\n",
    "print(a.values())\n",
    "\n",
    "#show for loop over all entries\n",
    "# option 1 using zip\n",
    "# this works also for iterating over any\n",
    "# other two lists\n",
    "for k,v in zip(a.keys(), a.values()):\n",
    "    print(k,v)\n",
    "\n",
    "# option 2 using the dictionary items()` function\n",
    "print(\"---\")\n",
    "for k,v in a.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mapreduce': 0, 'spark': 0} 0\n",
      "How many websites still to go?  10\n"
     ]
    }
   ],
   "source": [
    "# This code below does the trick, but could be optimized for speed if necessary\n",
    "# e.g. skills are typically listed at the end of the webpage\n",
    "# might not need to split/join the whole webpage, as we already know\n",
    "# which words we are looking for \n",
    "# and could stop after the first occurance of each word\n",
    "\n",
    "with open('C:\\\\Users\\\\Seif\\\\OneDrive\\\\Documents\\\\cs209\\\\2015\\\\Lectures\\\\data\\\\scraped_links_restart.pkl', 'rb') as f:\n",
    "    skill_set, index = pickle.load(f)\n",
    "    print(skill_set,index)\n",
    "    print(\"How many websites still to go? \", len(job_links) - index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.indeed.com/rc/clk?jk=9627034d8cd27792\n",
      "http://www.indeed.com/rc/clk?jk=1a622fdca8324636\n",
      "http://www.indeed.com/rc/clk?jk=43cbd0278042f1a9\n",
      "http://www.indeed.com/rc/clk?jk=90d9ce0ec817ce5d\n",
      "http://www.indeed.com/rc/clk?jk=f4a9d97c8c38a1bd\n",
      "5\n",
      "{'mapreduce': 0, 'spark': 0}\n",
      "http://www.indeed.com/rc/clk?jk=6cafcb785bf65e38\n",
      "http://www.indeed.com/rc/clk?jk=393d33212c837508\n",
      "HTTPError:\n",
      "http://www.indeed.com/rc/clk?jk=88e81abcc346e95d\n",
      "http://www.indeed.com/rc/clk?jk=dfc0cfbf1931b500\n",
      "http://www.indeed.com/rc/clk?jk=dd7b858f3353173f\n",
      "0\n",
      "{'mapreduce': 0, 'spark': 1}\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for link in job_links[index:]:\n",
    "    print(link)\n",
    "    counter +=1  \n",
    "    \n",
    "    try:\n",
    "        html_page = urllib2.urlopen(link).read()\n",
    "    except urllib2.HTTPError:\n",
    "        print(\"HTTPError:\")\n",
    "        continue\n",
    "    except urllib2.URLError:\n",
    "        print( \"URLError:\")\n",
    "        continue\n",
    "    except socket.error as error:\n",
    "        print( \"Connection closed\")\n",
    "        continue\n",
    "\n",
    "    html_text = re.sub(\"[^a-z.+3]\",\" \", html_page.lower().decode('utf-8')) # replace all but the listed characters\n",
    "        \n",
    "    for key in skill_set.keys():\n",
    "        if key in html_text:  \n",
    "            skill_set[key] +=1\n",
    "            \n",
    "    if counter % 5 == 0:\n",
    "        print (len(job_links) - counter - index)\n",
    "        print (skill_set)\n",
    "        with open('scraped_links_restart.pkl','wb') as f:\n",
    "            pickle.dump((skill_set, index+counter),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mapreduce': 0, 'spark': 1}\n"
     ]
    }
   ],
   "source": [
    "print (skill_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pseries = pd.Series(skill_set)\n",
    "pseries.sort_values(ascending=False)\n",
    "\n",
    "pseries.plot(kind = 'bar')\n",
    "## set the title to Score Comparison\n",
    "plt.title('Data Science Skills')\n",
    "## set the x label\n",
    "plt.xlabel('Skills')\n",
    "## set the y label\n",
    "plt.ylabel('Count')\n",
    "## show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another Example\n",
    "================\n",
    "\n",
    "Designed by Katharine Jarmul\n",
    "----------------------------\n",
    "\n",
    "https://github.com/kjam/python-web-scraping-tutorial\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scraping Happy Hours\n",
    "====================\n",
    "\n",
    "Scrape the happy hour list of LA for personal preferences\n",
    "\n",
    "http://www.downtownla.com/3_10_happyHours.asp?action=ALL\n",
    "\n",
    "This example is part of her talk about data scraping at PyCon2014. She is a really good speaker and I enjoyed watching her talk. Check it out: http://www.youtube.com/watch?v=p1iX0uxM1w8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-e0ae16f8ba38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lxml\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\beautifulsoup4-4.8.0-py3.6.egg\\bs4\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[0;32m    206\u001b[0m                     \u001b[1;34m\"Couldn't find a tree builder with the features you \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                     \u001b[1;34m\"requested: %s. Do you need to install a parser library?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m                     % \",\".join(features))\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;31m# At this point either we have a TreeBuilder instance in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "stuff_i_like = ['burger', 'sushi', 'sweet potato fries', 'BBQ','beer']\n",
    "found_happy_hours = []\n",
    "my_happy_hours = []\n",
    "# First, I'm going to identify the areas of the page I want to look at\n",
    "url = 'https://www.downtownla.com/explore/dining-nightlife/happy-hour-finder'\n",
    "source = urllib.request.urlopen(url).read()\n",
    "\n",
    "tables = bs4.BeautifulSoup(urllib.request.urlopen(url).read(), \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scraper found 56 happy hours!\n"
     ]
    }
   ],
   "source": [
    "# Then, I'm going to sort out the *exact* parts of the page\n",
    "# that match what I'm looking for...\n",
    "for t in tables.findAll('p'):\n",
    "    text = t.text\n",
    "    for s in t.findNextSiblings():\n",
    "        text += '\\n' + s.text\n",
    "    found_happy_hours.append(text)\n",
    "\n",
    "print(\"The scraper found %d happy hours!\" % len(found_happy_hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAY! I found some sushi!\n",
      "YAY! I found some beer!\n",
      "YAY! I found some beer!\n",
      "YAY! I found some beer!\n",
      "YAY! I found some beer!\n",
      "I think you might like 5 of them, yipeeeee!\n"
     ]
    }
   ],
   "source": [
    "# Now I'm going to loop through the food I like\n",
    "# and see if any of the happy hour descriptions match\n",
    "for food in stuff_i_like:\n",
    "    for hh in found_happy_hours:\n",
    "        # checking for text AND making sure I don't have duplicates\n",
    "        if food in hh and hh not in my_happy_hours:\n",
    "            print(\"YAY! I found some %s!\" % food)\n",
    "            my_happy_hours.append(hh)\n",
    "\n",
    "print(\"I think you might like %d of them, yipeeeee!\" % len(my_happy_hours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Now, let's make a mail message we can read:\n",
    "message = 'Hey Katharine,\\n\\n\\n'\n",
    "message += 'OMG, I found some stuff for you in Downtown, take a look.\\n\\n'\n",
    "message += '==============================\\n'.join(my_happy_hours)\n",
    "message = message.encode('utf-8')\n",
    "# To read more about encoding:\n",
    "# http://diveintopython.org/xml_processing/unicode.html\n",
    "message = message.replace('\\t', '').replace('\\r', '')\n",
    "message += '\\n\\nXOXO,\\n Your Py Script'\n",
    "\n",
    "#print message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Getting Data with an API\n",
    "=========================\n",
    "\n",
    "* API: application programming interface\n",
    "* some sites try to make your life easier\n",
    "* Twitter, New York Times, ImDB, rotten Tomatoes, Yelp, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rotten Tomatoes\n",
    "===============\n",
    "\n",
    "![The Wizard of Oz](images/wiz_oz.png \"The wizard of Oz\")\n",
    "\n",
    "http://www.rottentomatoes.com/top/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "API keys\n",
    "=========\n",
    "\n",
    "* required for data access\n",
    "* identifies application (you)\n",
    "* monitors usage\n",
    "* limits rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Rotten Tomatoes Key\n",
    "===================\n",
    "\n",
    "http://developer.rottentomatoes.com/member/register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "api_key = rottenTomatoes_key()\n",
    "\n",
    "url = 'http://api.rottentomatoes.com/api/public/v1.0/lists/dvds/top_rentals.json?apikey=' + api_key\n",
    "data = urllib2.urlopen(url).read()\n",
    "#print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "JSON\n",
    "======\n",
    "\n",
    "* JavaScript Object Notation\n",
    "* human readable\n",
    "* transmit attribute-value pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "a = {'a': 1, 'b':2}\n",
    "s = json.dumps(a)\n",
    "a2 = json.loads(s)\n",
    "\n",
    "## a is a dictionary\n",
    "print a\n",
    "## vs s is a string containing a in JSON encoding\n",
    "print s\n",
    "## reading back the keys are now in unicode\n",
    "print a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## create dictionary from JSON \n",
    "dataDict = json.loads(data)\n",
    "\n",
    "## expore dictionary\n",
    "print dataDict.keys()\n",
    "\n",
    "## there is a key named `movies` containing a list of movies as a value\n",
    "movies = dataDict['movies']\n",
    "\n",
    "## each element of the list `movies` is a dictionary\n",
    "print movies[0].keys()\n",
    "\n",
    "## one of the keys is called `ratings`\n",
    "## the value is yet another dictionary\n",
    "print movies[0]['ratings'].keys()\n",
    "\n",
    "## so we made it all the way to find the critics score\n",
    "print movies[0]['ratings']['critics_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Quiz\n",
    "=====\n",
    "\n",
    "* build a list with critics scores\n",
    "* build a list with audience scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# critics scores list\n",
    "\n",
    "\n",
    "# audience scores list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The following code shows how to create a pandas data frame with the data we gathered from the webpage.\n",
    "Beware of the `set_index()` function in pandas. Per default it does not change the actual data frame! You need to either reassign the output or set the `inplace` argument to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## create pandas data frame with critics and audience score\n",
    "scores = pd.DataFrame(data=[critics_scores, audience_scores]).transpose()\n",
    "scores.columns = ['critics', 'audience']\n",
    "\n",
    "## also create a list with all movie titles\n",
    "movie_titles = [m['title'] for m in movies]\n",
    "\n",
    "## set index of dataFrame BEWARE of inplace!\n",
    "scores.set_index([movie_titles])\n",
    "\n",
    "## the line above does not changes scores!\n",
    "## You need to either reassign\n",
    "\n",
    "scores = scores.set_index([movie_titles])\n",
    "\n",
    "## or set the inplace argument to True\n",
    "scores.set_index([movie_titles], inplace=True)\n",
    "scores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## create a bar plot with the data\n",
    "## notice that we are using the data frame itself and call its plot function\n",
    "scores.plot(kind = 'bar')\n",
    "\n",
    "## set the title to Score Comparison\n",
    "plt.title('Score Comparison')\n",
    "\n",
    "## set the x label\n",
    "plt.xlabel('Movies')\n",
    "\n",
    "## set the y label\n",
    "plt.ylabel('Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Twitter Example:\n",
    "================\n",
    "\n",
    "* API a bit more complicated\n",
    "* libraries make life easier\n",
    "* python-twitter\n",
    "\n",
    "https://github.com/bear/python-twitter\n",
    "\n",
    "What we are going to do is scrape Joe's twitter account, and then filter it for the interesting tweets. Defining interesting as tweets that have be re-tweeted at least 10 times. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_key\n",
      "c_secret\n",
      "a_token\n",
      "a_secret\n"
     ]
    }
   ],
   "source": [
    "# api keys are in config.ini to keep them outside of this public notebook\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "for key in config['DEFAULT']:  \n",
    "    print(key)\n",
    "twit = config['DEFAULT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import twitter\n",
    "\n",
    "## define the necessary keys\n",
    "cKey = twit[\"c_key\"]\n",
    "cSecret = twit[\"c_secret\"]\n",
    "aKey = twit[\"a_token\"]\n",
    "aSecret = twit[\"a_secret\"]\n",
    "\n",
    "## create the api object with the twitter-python library\n",
    "api = twitter.Api(consumer_key=cKey, consumer_secret=cSecret, access_token_key=aKey, access_token_secret=aSecret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?screen_name=Seif_mej&include_rts=True&trim_user=False&exclude_replies=False&tweet_mode=compat (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001EE93278F98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 160\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m         \u001b[0maf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    602\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sock'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 843\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    168\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 169\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x000001EE93278F98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    640\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 641\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    642\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?screen_name=Seif_mej&include_rts=True&trim_user=False&exclude_replies=False&tweet_mode=compat (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001EE93278F98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-a1e8a5868a23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstatuses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetUserTimeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Seif_mej'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstatuses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0musers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetFriends\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfriends\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfriend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfriend\u001b[0m \u001b[1;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36mGetUserTimeline\u001b[1;34m(self, user_id, screen_name, since_id, max_id, count, include_rts, trim_user, exclude_replies)\u001b[0m\n\u001b[0;32m    809\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'exclude_replies'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menf_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'exclude_replies'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude_replies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_RequestUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ParseAndCheckTwitter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\twitter\\api.py\u001b[0m in \u001b[0;36m_RequestUrl\u001b[1;34m(self, url, verb, data, json, enforce_auth)\u001b[0m\n\u001b[0;32m   4990\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tweet_mode'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtweet_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4991\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_BuildUrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextra_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4992\u001b[1;33m             \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__auth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4994\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GET'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\DeepLearning\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /1.1/statuses/user_timeline.json?screen_name=Seif_mej&include_rts=True&trim_user=False&exclude_replies=False&tweet_mode=compat (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x000001EE93278F98>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))"
     ]
    }
   ],
   "source": [
    "statuses = api.GetUserTimeline(screen_name='Seif_mej')\n",
    "texts=[s.text for s in statuses]\n",
    "\n",
    "users = api.GetFriends()\n",
    "friends=[friend.name for friend in users]\n",
    "# print(friends)\n",
    "status=api.GetSearch(term =\"Earthquake\",count =2)\n",
    "search_res=[s for s in status]\n",
    "print(search_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         2.0\n",
      "4       928.0\n",
      "5        39.0\n",
      "6         3.0\n",
      "7         NaN\n",
      "8         NaN\n",
      "9         NaN\n",
      "10        NaN\n",
      "11        NaN\n",
      "12    16752.0\n",
      "13        NaN\n",
      "14       38.0\n",
      "15        NaN\n",
      "16        NaN\n",
      "17        NaN\n",
      "18        NaN\n",
      "19        NaN\n",
      "Name: retweet_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## get the user timeline with screen_name = 'stat110'\n",
    "twitter_statuses = api.GetUserTimeline(screen_name = 'Seif_mej')\n",
    "\n",
    "## create a data frame\n",
    "## first get a list of panda Series or dict\n",
    "pdSeriesList = [pd.Series(t.AsDict()) for t in twitter_statuses]\n",
    "\n",
    "## then create the data frame\n",
    "data = pd.DataFrame(pdSeriesList)\n",
    "\n",
    "data.head(1)\n",
    "# print(data.retweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "RT @math_rachel: learn deep learning: https://t.co/MhwV380FWg\n",
      "computational linear algebra: https://t.co/CY7Gu8IXmZ\n",
      "data science career adv…\n",
      "------------------------------------\n",
      "RT @BecomingDataSci: When I see someone that is gatekeeping our field, it appears to me like they're afraid of the newcomers. Worried about…\n",
      "------------------------------------\n",
      "RT @dwddao: Time to rethink #data as #labor. In our most recent #AISTATS2019 paper, we leverage cooperative game theory to provide a theore…\n",
      "------------------------------------\n",
      "RT @LFC: P A S S I O N 👊 https://t.co/A0ZccOGxJy\n",
      "------------------------------------\n",
      "RT @Reuters: Slack valued at $5.1 billion after new funding led by SoftBank https://t.co/tEI6JLlUNC https://t.co/m9X8ViaToY\n"
     ]
    }
   ],
   "source": [
    "## filter tweets with enough retweet_count\n",
    "maybe_interesting = data[data.retweet_count>2]\n",
    "\n",
    "## get the text of these tweets\n",
    "tweet_text = maybe_interesting.text\n",
    "\n",
    "## print them out\n",
    "text = tweet_text.values\n",
    "\n",
    "for t in text:\n",
    "    print('---'*12)\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_key\n",
      "c_secret\n",
      "a_token\n",
      "a_secret\n",
      "seifeddine\n"
     ]
    }
   ],
   "source": [
    "# api keys are in config.ini to keep them outside of this public notebook\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "for key in config['DEFAULT']:  \n",
    "    print(key)\n",
    "twit = config['DEFAULT']\n",
    "#OAuth authentication \n",
    "#this is the new mode of authenticatino in tweet\n",
    "#The consumer key \n",
    "consumer_key = twit[\"c_key\"]\n",
    "consumer_secret = twit[\"c_secret\"]\n",
    "#the access tokens can be found on application details\n",
    "#page located at https://dev.twitter.com/apps (under \"OAuth settings\")\n",
    "access_token = twit[\"a_token\"] \n",
    "access_token_secret = twit[\"a_secret\"]\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api=tweepy.API(auth)\n",
    "#If the authenticatino was successful; this should output my name \n",
    "print(api.me().name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.update_status(status='Updating using OAuth authentication via Tweepy!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Extracting columns:\n",
    "===================\n",
    "\n",
    "__Warning:__ The returned column `tweet_text` is a `view` on the data\n",
    "    \n",
    "* it is not a copy\n",
    "* you change the Series => you change the DataFrame\n",
    "\n",
    "Below is another example of such a view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print('-----------------')? (<ipython-input-64-13aac039e5d4>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-64-13aac039e5d4>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print '-----------------'\u001b[0m\n\u001b[1;37m                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print('-----------------')?\n"
     ]
    }
   ],
   "source": [
    "## create a view for favorite_count on maybe_interesting\n",
    "view = maybe_interesting['favorite_count']\n",
    "print '-----------------'\n",
    "print \"This is view:\"\n",
    "print view\n",
    "## change a value\n",
    "view[8] = 9999\n",
    "\n",
    "## look at original frame\n",
    "print '-----------------'\n",
    "print \"This is view after changing view[8]\"\n",
    "print view\n",
    "\n",
    "print '-----------------'\n",
    "print \"This is maybe_interesting after changing view[8]\"\n",
    "print \"It changed too!\"\n",
    "print maybe_interesting['favorite_count']\n",
    "\n",
    "## to avoid this you can use copy\n",
    "independent_data = maybe_interesting['favorite_count'].copy()\n",
    "independent_data[10] = 999\n",
    "print '-----------------'\n",
    "print \"This is independent_data after changed at 10:\"\n",
    "print independent_data\n",
    "print '-----------------'\n",
    "print \"This is maybe_interesting after changing independent_data:\"\n",
    "print \"It did not change because we only changed a copy of it\"\n",
    "print maybe_interesting['favorite_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What we covered today:\n",
    "============\n",
    "\n",
    "* Pandas data frames\n",
    "* Guidelines for friendly scraping\n",
    "* Scraping html sites\n",
    "* Scraping with Api's\n",
    "* Basic data cleanup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Further material\n",
    "================\n",
    "\n",
    "* I highly recommend Katharine Jarmul's scraping tutorials\n",
    "* For example [this one](https://www.youtube.com/watch?v=p1iX0uxM1w8)\n",
    "* Pandas has extensive [documentation](http://pandas.pydata.org/pandas-docs/stable/)\n",
    "* Especially the [tem minutes to pandas chapter](http://pandas.pydata.org/pandas-docs/stable/10min.html)\n",
    "\n",
    "* [Greg Reda](http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/) did a lot more pandas examples for the movie lens data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
